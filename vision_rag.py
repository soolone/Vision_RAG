import os
import io
import base64
import PIL
from PIL import Image
import numpy as np
import streamlit as st
import cohere
import google.generativeai as genai
import fitz # PyMuPDF
from typing import List, Dict, Tuple
from collections import defaultdict

# Import query expansion agent
try:
    from agent.query_agent import QueryExpansionAgent
except ImportError:
    QueryExpansionAgent = None

# --- Constants ---
max_pixels = 1568*1568  # Max resolution for images

# --- Helper functions ---

# Resize too large images
def resize_image(pil_image: PIL.Image.Image) -> None:
    """Resizes the image in-place if it exceeds max_pixels."""
    org_width, org_height = pil_image.size

    # Resize image if too large
    if org_width * org_height > max_pixels:
        scale_factor = (max_pixels / (org_width * org_height)) ** 0.5
        new_width = int(org_width * scale_factor)
        new_height = int(org_height * scale_factor)
        pil_image.thumbnail((new_width, new_height))

# Convert images to a base64 string before sending it to the API
def base64_from_image(img_path: str) -> str:
    """Converts an image file to a base64 encoded string."""
    pil_image = PIL.Image.open(img_path)
    img_format = pil_image.format if pil_image.format else "PNG"

    resize_image(pil_image)

    with io.BytesIO() as img_buffer:
        pil_image.save(img_buffer, format=img_format)
        img_buffer.seek(0)
        img_data = f"data:image/{img_format.lower()};base64,"+base64.b64encode(img_buffer.read()).decode("utf-8")

    return img_data

# Convert PIL image to base64 string
def pil_to_base64(pil_image: PIL.Image.Image) -> str:
    """Converts a PIL image to a base64 encoded string."""
    if pil_image.format is None:
        img_format = "PNG"
    else:
        img_format = pil_image.format
    
    resize_image(pil_image)

    with io.BytesIO() as img_buffer:
        pil_image.save(img_buffer, format=img_format)
        img_buffer.seek(0)
        img_data = f"data:image/{img_format.lower()};base64,"+base64.b64encode(img_buffer.read()).decode("utf-8")

    return img_data

# Compute embedding for an image
@st.cache_data(ttl=3600, show_spinner=False)
def compute_image_embedding(base64_img: str, _cohere_client) -> np.ndarray | None:
    """Computes an embedding for an image using Cohere's Embed-4 model."""
    try:
        api_response = _cohere_client.embed(
            model="embed-v4.0",
            input_type="search_document",
            embedding_types=["float"],
            images=[base64_img],
        )
        
        if api_response.embeddings and api_response.embeddings.float:
            return np.asarray(api_response.embeddings.float[0])
        else:
            st.warning("æ— æ³•è·å–åµŒå…¥å‘é‡ã€‚API å“åº”å¯èƒ½ä¸ºç©ºã€‚")
            return None
    except Exception as e:
        st.error(f"è®¡ç®—åµŒå…¥å‘é‡æ—¶å‡ºé”™ï¼š{e}")
        return None

# Process a PDF file: extract pages as images and embed them
# Note: Caching PDF processing might be complex due to potential large file sizes and streams
# We will process it directly for now, but show progress.
def process_pdf_file(pdf_file, cohere_client, base_output_folder="pdf_pages") -> tuple[list[str], list[np.ndarray] | None]:
    """Extracts pages from a PDF as images, embeds them, and saves them.

    Args:
        pdf_file: UploadedFile object from Streamlit.
        cohere_client: Initialized Cohere client.
        base_output_folder: Directory to save page images.

    Returns:
        A tuple containing: 
          - list of paths to the saved page images.
          - list of numpy array embeddings for each page, or None if embedding fails.
    """
    page_image_paths = []
    page_embeddings = []
    pdf_filename = pdf_file.name
    output_folder = os.path.join(base_output_folder, os.path.splitext(pdf_filename)[0])
    os.makedirs(output_folder, exist_ok=True)

    try:
        # Open PDF from stream
        doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
        st.write(f"æ­£åœ¨å¤„ç† PDFï¼š{pdf_filename} ({len(doc)} é¡µ)")
        pdf_progress = st.progress(0.0)

        for i, page in enumerate(doc.pages()):
            page_num = i + 1
            page_img_path = os.path.join(output_folder, f"page_{page_num}.png")
            page_image_paths.append(page_img_path)

            # Render page to pixmap (image)
            pix = page.get_pixmap(dpi=150) # Adjust DPI as needed for quality/performance
            pil_image = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            
            # Save the page image temporarily
            pil_image.save(page_img_path, "PNG")
            
            # Convert PIL image to base64
            base64_img = pil_to_base64(pil_image)
            
            # Compute embedding for the page image
            emb = compute_image_embedding(base64_img, _cohere_client=cohere_client)
            if emb is not None:
                page_embeddings.append(emb)
            else:
                st.warning(f"æ— æ³•åµŒå…¥ {pdf_filename} çš„ç¬¬ {page_num} é¡µã€‚è·³è¿‡ã€‚")
                # Add a placeholder to keep lists aligned, will be filtered later
                page_embeddings.append(None)

            # Update progress
            pdf_progress.progress((i + 1) / len(doc))

        doc.close()
        pdf_progress.empty() # Remove progress bar after completion
        
        # Filter out pages where embedding failed
        valid_paths = [path for i, path in enumerate(page_image_paths) if page_embeddings[i] is not None]
        valid_embeddings = [emb for emb in page_embeddings if emb is not None]
        
        if not valid_embeddings:
             st.error(f"æ— æ³•ä¸º {pdf_filename} ç”Ÿæˆä»»ä½•åµŒå…¥å‘é‡ã€‚")
             return [], None

        return valid_paths, valid_embeddings

    except Exception as e:
        st.error(f"å¤„ç† PDF {pdf_filename} æ—¶å‡ºé”™ï¼š{e}")
        return [], None



# Reciprocal Rank Fusion (RRF) algorithm
def reciprocal_rank_fusion(rankings: List[List[Tuple[int, float]]], k: int = 60) -> List[Tuple[int, float]]:
    """Apply Reciprocal Rank Fusion to combine multiple rankings.
    
    Args:
        rankings: List of rankings, each ranking is a list of (index, score) tuples
        k: RRF parameter (smoothing factor)
        
    Returns:
        Fused ranking as list of (index, fused_score) tuples
    """
    rrf_scores = defaultdict(float)
    
    for ranking in rankings:
        for rank, (doc_idx, _) in enumerate(ranking):
            # RRF formula: 1 / (k + rank)
            rrf_scores[doc_idx] += 1.0 / (k + rank + 1)  # +1 because rank is 0-indexed
    
    # Sort by RRF score (descending)
    fused_ranking = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)
    return fused_ranking

# Multi-query search with RRF fusion
def multi_query_search(queries: List[str], co_client: cohere.Client, embeddings: np.ndarray, image_paths: list[str], top_k: int = 3) -> List[Tuple[str, float]] | None:
    """Perform multi-query search with RRF fusion.
    
    Args:
        queries: List of query strings
        co_client: Cohere client
        embeddings: Document embeddings
        image_paths: List of image paths
        top_k: Number of top results to return
        
    Returns:
        List of (image_path, score) tuples for top-k results
    """
    if not co_client or embeddings is None or embeddings.size == 0 or not image_paths:
        st.warning("å¤šæŸ¥è¯¢æœç´¢å‰ææ¡ä»¶ä¸æ»¡è¶³ï¼ˆå®¢æˆ·ç«¯ã€åµŒå…¥å‘é‡æˆ–è·¯å¾„ç¼ºå¤±/ä¸ºç©ºï¼‰ã€‚")
        return None
    
    if embeddings.shape[0] != len(image_paths):
        st.error(f"åµŒå…¥å‘é‡æ•°é‡ ({embeddings.shape[0]}) ä¸å›¾ç‰‡è·¯å¾„æ•°é‡ ({len(image_paths)}) ä¸åŒ¹é…ã€‚æ— æ³•æ‰§è¡Œæœç´¢ã€‚")
        return None
    
    try:
        # Get embeddings for all queries
        api_response = co_client.embed(
            model="embed-v4.0",
            input_type="search_query",
            embedding_types=["float"],
            texts=queries,
        )
        
        if not api_response.embeddings or not api_response.embeddings.float:
            st.error("è·å–æŸ¥è¯¢åµŒå…¥å‘é‡å¤±è´¥ã€‚")
            return None
        
        query_embeddings = np.array(api_response.embeddings.float)
        
        # Ensure query embeddings have the correct shape
        if query_embeddings.shape[1] != embeddings.shape[1]:
            st.error(f"æŸ¥è¯¢åµŒå…¥å‘é‡ç»´åº¦ ({query_embeddings.shape[1]}) ä¸æ–‡æ¡£åµŒå…¥å‘é‡ç»´åº¦ ({embeddings.shape[1]}) ä¸åŒ¹é…ã€‚")
            return None
        
        # Compute similarities for each query and create rankings
        rankings = []
        for i, query_emb in enumerate(query_embeddings):
            # Compute cosine similarities
            cos_sim_scores = np.dot(query_emb, embeddings.T)
            
            # Create ranking (sorted by similarity, descending)
            ranking = [(idx, score) for idx, score in enumerate(cos_sim_scores)]
            ranking.sort(key=lambda x: x[1], reverse=True)
            rankings.append(ranking)
            
            print(f"Query {i+1}: '{queries[i]}' - Top result: {image_paths[ranking[0][0]]} (score: {ranking[0][1]:.4f})")
        
        # Apply RRF fusion
        fused_ranking = reciprocal_rank_fusion(rankings)
        
        # Get the top-k results
        if fused_ranking:
            top_k_results = []
            for i in range(min(top_k, len(fused_ranking))):
                idx = fused_ranking[i][0]
                score = fused_ranking[i][1]
                img_path = image_paths[idx]
                top_k_results.append((img_path, score))
                print(f"RRF Fusion result {i+1}: {img_path} (RRF score: {score:.4f})")
            return top_k_results
        else:
            return None
            
    except Exception as e:
        st.error(f"å¤šæŸ¥è¯¢æœç´¢è¿‡ç¨‹ä¸­å‡ºé”™ï¼š{e}")
        return None

# Original single query search function
def search(question: str, co_client: cohere.Client, embeddings: np.ndarray, image_paths: list[str], top_k: int = 3, max_img_size: int = 800) -> List[Tuple[str, float]] | None:
    """Finds the most relevant image paths for a given question.
    
    Args:
        question: Query string
        co_client: Cohere client
        embeddings: Document embeddings
        image_paths: List of image paths
        top_k: Number of top results to return
        max_img_size: Maximum image size (unused)
        
    Returns:
        List of (image_path, score) tuples for top-k results
    """
    if not co_client or embeddings is None or embeddings.size == 0 or not image_paths:
        st.warning("æœç´¢å‰ææ¡ä»¶ä¸æ»¡è¶³ï¼ˆå®¢æˆ·ç«¯ã€åµŒå…¥å‘é‡æˆ–è·¯å¾„ç¼ºå¤±/ä¸ºç©ºï¼‰ã€‚")
        return None
    if embeddings.shape[0] != len(image_paths):
         st.error(f"åµŒå…¥å‘é‡æ•°é‡ ({embeddings.shape[0]}) ä¸å›¾ç‰‡è·¯å¾„æ•°é‡ ({len(image_paths)}) ä¸åŒ¹é…ã€‚æ— æ³•æ‰§è¡Œæœç´¢ã€‚")
         return None

    try:
        # Compute the embedding for the query
        api_response = co_client.embed(
            model="embed-v4.0",
            input_type="search_query",
            embedding_types=["float"],
            texts=[question],
        )

        if not api_response.embeddings or not api_response.embeddings.float:
            st.error("è·å–æŸ¥è¯¢åµŒå…¥å‘é‡å¤±è´¥ã€‚")
            return None

        query_emb = np.asarray(api_response.embeddings.float[0])

        # Ensure query embedding has the correct shape for dot product
        if query_emb.shape[0] != embeddings.shape[1]:
            st.error(f"æŸ¥è¯¢åµŒå…¥å‘é‡ç»´åº¦ ({query_emb.shape[0]}) ä¸æ–‡æ¡£åµŒå…¥å‘é‡ç»´åº¦ ({embeddings.shape[1]}) ä¸åŒ¹é…ã€‚")
            return None

        # Compute cosine similarities
        cos_sim_scores = np.dot(query_emb, embeddings.T)

        # Get the top-k most relevant images
        top_indices = np.argsort(cos_sim_scores)[::-1][:top_k]  # Sort descending and take top-k
        top_k_results = []
        
        print(f"Question: {question}") # Keep for debugging
        for i, idx in enumerate(top_indices):
            img_path = image_paths[idx]
            score = cos_sim_scores[idx]
            top_k_results.append((img_path, score))
            print(f"Result {i+1}: {img_path} (score: {score:.4f})") # Keep for debugging

        return top_k_results
    except Exception as e:
        st.error(f"æœç´¢è¿‡ç¨‹ä¸­å‡ºé”™ï¼š{e}")
        return None

# Answer function for multiple images
def answer_multiple(question: str, img_results: List[Tuple[str, float]], gemini_client) -> str:
    """Answers the question based on multiple provided images using Gemini."""
    if not gemini_client or not img_results:
        missing = []
        if not gemini_client: missing.append("Gemini client")
        if not img_results: missing.append("Image results")
        return f"å›ç­”å‰ææ¡ä»¶ä¸æ»¡è¶³ï¼ˆ{', '.join(missing)} ç¼ºå¤±æˆ–æ— æ•ˆï¼‰ã€‚"
    
    try:
        # Prepare images and prompt
        valid_images = []
        image_info = []
        
        for i, (img_path, score) in enumerate(img_results):
            if os.path.exists(img_path):
                img = PIL.Image.open(img_path)
                valid_images.append(img)
                
                # Create image description for prompt
                source_info = os.path.basename(img_path)
                if img_path.startswith("pdf_pages/"):
                    parts = img_path.split(os.sep)
                    if len(parts) >= 3:
                        pdf_name = parts[1]
                        page_name = parts[-1]
                        source_info = f"{pdf_name}.pdfï¼Œ{page_name.replace('.png','')}"
                
                image_info.append(f"å›¾ç‰‡{i+1}ï¼ˆæ¥æºï¼š{source_info}ï¼Œç›¸å…³åº¦ï¼š{score:.3f}ï¼‰")
        
        if not valid_images:
            return "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶ã€‚"
        
        # Create comprehensive prompt
        prompt_text = f"""è¯·åŸºäºä»¥ä¸‹{len(valid_images)}å¼ ç›¸å…³å›¾ç‰‡å›ç­”é—®é¢˜ã€‚è¯·ç»¼åˆåˆ†ææ‰€æœ‰å›¾ç‰‡çš„å†…å®¹ï¼Œæä¾›å…¨é¢è¯¦ç»†çš„ç­”æ¡ˆã€‚

é—®é¢˜ï¼š{question}

å›¾ç‰‡ä¿¡æ¯ï¼š
{chr(10).join(image_info)}

è¯·æ³¨æ„ï¼š
1. ç»¼åˆåˆ†ææ‰€æœ‰å›¾ç‰‡çš„å†…å®¹
2. å¦‚æœå›¾ç‰‡å†…å®¹ç›¸å…³ï¼Œè¯·æ•´åˆä¿¡æ¯æä¾›å®Œæ•´ç­”æ¡ˆ
3. å¦‚æœå›¾ç‰‡å†…å®¹ä¸åŒï¼Œè¯·åˆ†åˆ«è¯´æ˜æ¯å¼ å›¾ç‰‡çš„ç›¸å…³ä¿¡æ¯
4. è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¯¹äºä¸“ä¸šæœ¯è¯­è¯·ä½¿ç”¨å‡†ç¡®çš„ä¸­æ–‡è¡¨è¾¾
5. ä¸è¦ä½¿ç”¨markdownæ ¼å¼
6. æä¾›å……åˆ†çš„ä¸Šä¸‹æ–‡èƒŒæ™¯"""
        
        # Prepare content for API call
        prompt_content = [prompt_text] + valid_images
        
        response = gemini_client.models.generate_content(
            model="gemini-2.5-flash-preview-04-17",
            contents=prompt_content
        )
        
        llm_answer = response.text
        print(f"LLM Answer for {len(valid_images)} images:", llm_answer) # Keep for debugging
        return llm_answer
        
    except Exception as e:
        st.error(f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™ï¼š{e}")
        return f"ç”Ÿæˆç­”æ¡ˆå¤±è´¥ï¼š{e}"

# Answer function (single image, kept for compatibility)
def answer(question: str, img_path: str, gemini_client) -> str:
    """Answers the question based on the provided image using Gemini."""
    return answer_multiple(question, [(img_path, 1.0)], gemini_client)




def initialize_session_state():
    """åˆå§‹åŒ–Streamlitä¼šè¯çŠ¶æ€å˜é‡"""
    if 'image_paths' not in st.session_state:
        st.session_state.image_paths = []
    if 'doc_embeddings' not in st.session_state:
        st.session_state.doc_embeddings = None
    if 'use_query_expansion' not in st.session_state:
        st.session_state.use_query_expansion = True
    if 'processed_files' not in st.session_state:
        st.session_state.processed_files = set()
    if 'num_results' not in st.session_state:
        st.session_state.num_results = 3

def setup_sidebar():
    """è®¾ç½®ä¾§è¾¹æ UIå¹¶è¿”å›APIå¯†é’¥å’Œè®¾ç½®"""
    with st.sidebar:
        st.header("ğŸ”‘ API å¯†é’¥")
        cohere_api_key = st.text_input("Cohere API å¯†é’¥", type="password", key="cohere_key")
        google_api_key = st.text_input("Google API å¯†é’¥ (Gemini)", type="password", key="google_key")
        "[è·å– Cohere API å¯†é’¥](https://dashboard.cohere.com/api-keys)"
        "[è·å– Google API å¯†é’¥](https://aistudio.google.com/app/apikey)"

        st.markdown("---")
        if not cohere_api_key:
            st.warning("è¯·è¾“å…¥æ‚¨çš„ Cohere API å¯†é’¥ä»¥ç»§ç»­ã€‚")
        if not google_api_key:
            st.warning("è¯·è¾“å…¥æ‚¨çš„ Google API å¯†é’¥ä»¥ç»§ç»­ã€‚")
        
        st.markdown("---")
        st.header("ğŸ”§ é«˜çº§è®¾ç½®")
        use_query_expansion = st.checkbox(
            "å¯ç”¨æŸ¥è¯¢æ‰©å±•", 
            value=st.session_state.use_query_expansion,
            help="ä½¿ç”¨AIç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“å¹¶èåˆç»“æœï¼Œæé«˜æ£€ç´¢å‡†ç¡®æ€§"
        )
        st.session_state.use_query_expansion = use_query_expansion
        
        if use_query_expansion and QueryExpansionAgent is None:
            st.warning("âš ï¸ æŸ¥è¯¢æ‰©å±•ä»£ç†ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨åŸå§‹æŸ¥è¯¢æ¨¡å¼")
        
        # Add setting for number of results to return
        num_results = st.slider(
            "è¿”å›ç»“æœæ•°é‡",
            min_value=1,
            max_value=10,
            value=st.session_state.num_results,
            help="è®¾ç½®æ£€ç´¢è¿”å›çš„ç›¸å…³å›¾ç‰‡æ•°é‡"
        )
        st.session_state.num_results = num_results
        
        st.markdown("---")
    
    return cohere_api_key, google_api_key

def initialize_api_clients(cohere_api_key, google_api_key):
    """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
    co = None
    genai_client = None
    query_agent = None
    
    if cohere_api_key and google_api_key:
        try:
            co = cohere.ClientV2(api_key=cohere_api_key)
            st.sidebar.success("Cohere å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼")
        except Exception as e:
            st.sidebar.error(f"Cohere åˆå§‹åŒ–å¤±è´¥ï¼š{e}")

        try:
            genai_client = genai.Client(api_key=google_api_key)
            st.sidebar.success("Gemini å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼")
        except Exception as e:
            st.sidebar.error(f"Gemini åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
        
        # Initialize query expansion agent
        if st.session_state.use_query_expansion and QueryExpansionAgent:
            try:
                query_agent = QueryExpansionAgent()
                st.sidebar.success("æŸ¥è¯¢æ‰©å†™ä»£ç†åˆå§‹åŒ–æˆåŠŸï¼")
            except Exception as e:
                st.sidebar.error(f"æŸ¥è¯¢æ‰©å†™ä»£ç†åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
                query_agent = None
    else:
        st.info("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ API å¯†é’¥ä»¥å¼€å§‹ä½¿ç”¨ã€‚")
    
    return co, genai_client, query_agent

def show_model_info():
    """æ˜¾ç¤ºæ¨¡å‹å’ŒæŠ€æœ¯ä¿¡æ¯"""
    with st.expander("â„¹ï¸ å…³äºä½¿ç”¨çš„æ¨¡å‹å’ŒæŠ€æœ¯"):
        st.markdown("""
        ### Cohere Embed-4
        
        Cohere çš„ Embed-4 æ˜¯ä¸€ä¸ªä¸ºä¼ä¸šæœç´¢å’Œæ£€ç´¢è®¾è®¡çš„æœ€å…ˆè¿›çš„å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹ã€‚
        å®ƒå…·æœ‰ä»¥ä¸‹åŠŸèƒ½ï¼š
        
        - **å¤šæ¨¡æ€æœç´¢**ï¼šæ— ç¼åœ°åŒæ—¶æœç´¢æ–‡æœ¬å’Œå›¾åƒ
        - **é«˜ç²¾åº¦**ï¼šåœ¨æ£€ç´¢ä»»åŠ¡ä¸­å…·æœ‰æœ€å…ˆè¿›çš„æ€§èƒ½
        - **é«˜æ•ˆåµŒå…¥**ï¼šå¤„ç†å¤æ‚å›¾åƒï¼Œå¦‚å›¾è¡¨ã€å›¾å½¢å’Œä¿¡æ¯å›¾
        
        è¯¥æ¨¡å‹æ— éœ€å¤æ‚çš„ OCR é¢„å¤„ç†å³å¯å¤„ç†å›¾åƒï¼Œå¹¶ä¿æŒè§†è§‰å…ƒç´ ä¸æ–‡æœ¬ä¹‹é—´çš„è¿æ¥ã€‚
        
        ### Google Gemini 2.5 Flash
        
        Gemini 2.5 Flash æ˜¯ Google çš„é«˜æ•ˆå¤šæ¨¡æ€æ¨¡å‹ï¼Œå¯ä»¥å¤„ç†æ–‡æœ¬å’Œå›¾åƒè¾“å…¥ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å“åº”ã€‚
        å®ƒä¸“ä¸ºå¿«é€Ÿæ¨ç†è€Œè®¾è®¡ï¼ŒåŒæ—¶ä¿æŒé«˜ç²¾åº¦ï¼Œéå¸¸é€‚åˆåƒè¿™ä¸ª RAG ç³»ç»Ÿè¿™æ ·çš„å®æ—¶åº”ç”¨ã€‚
        
        ### æŸ¥è¯¢æ‰©å±•ä¸å¤šæŸ¥è¯¢èåˆ ğŸ”
        
        æœ¬ç³»ç»Ÿé›†æˆäº†å…ˆè¿›çš„æŸ¥è¯¢ä¼˜åŒ–æŠ€æœ¯ï¼š
        
        - **æ™ºèƒ½æŸ¥è¯¢æ‰©å±•**ï¼šä½¿ç”¨ Qwen3-235B-A22B æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆå¤šä¸ªè‹±æ–‡æŸ¥è¯¢å˜ä½“
        - **è¯­ä¹‰å¤šæ ·åŒ–**ï¼šé€šè¿‡åŒä¹‰è¯ã€ç›¸å…³æ¦‚å¿µå’Œä¸åŒè¡¨è¾¾æ–¹å¼æ‰©å±•æŸ¥è¯¢
        - **RRF èåˆç®—æ³•**ï¼šé‡‡ç”¨ Reciprocal Rank Fusion ç®—æ³•èåˆå¤šä¸ªæŸ¥è¯¢ç»“æœ
        - **æå‡æ£€ç´¢ç²¾åº¦**ï¼šæ˜¾è‘—æé«˜æ£€ç´¢ç›¸å…³æ€§å’Œå‡†ç¡®æ€§ï¼Œå‡å°‘è¯æ±‡ä¸åŒ¹é…é—®é¢˜
        
        å¯ç”¨æŸ¥è¯¢æ‰©å±•åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆ 3-5 ä¸ªæŸ¥è¯¢å˜ä½“ï¼Œå¹¶ä½¿ç”¨ RRF ç®—æ³•èåˆç»“æœï¼Œä¸ºæ‚¨æä¾›æ›´ç²¾å‡†çš„ç­”æ¡ˆã€‚
        """)

def handle_file_upload(co):
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ é€»è¾‘"""
    st.subheader("ğŸ“¤ ä¸Šä¼ æ‚¨çš„å›¾ç‰‡")
    st.info("ä¸Šä¼ æ‚¨çš„å›¾ç‰‡æˆ– PDF æ–‡ä»¶ã€‚RAG è¿‡ç¨‹å°†åœ¨æ‰€æœ‰å·²åŠ è½½çš„å†…å®¹ä¸­è¿›è¡Œæœç´¢ã€‚")

    # File uploader
    uploaded_files = st.file_uploader("ä¸Šä¼ å›¾ç‰‡ (PNG, JPG, JPEG) æˆ– PDF æ–‡ä»¶", 
                                    type=["png", "jpg", "jpeg", "pdf"], 
                                    accept_multiple_files=True, key="image_uploader",
                                    label_visibility="collapsed")

    # Show uploaded files info and process button
    if uploaded_files:
        st.write(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        # Show file list
        for uploaded_file in uploaded_files:
            file_status = "âœ… å·²å¤„ç†" if uploaded_file.name in st.session_state.processed_files else "â³ å¾…å¤„ç†"
            st.write(f"- {uploaded_file.name} ({uploaded_file.type}) {file_status}")
        
        # Process button - only show if there are unprocessed files and API keys are available
        unprocessed_files = [f for f in uploaded_files if f.name not in st.session_state.processed_files]
        
        if unprocessed_files and co:
            if st.button(f"å¤„ç† {len(unprocessed_files)} ä¸ªæ–°æ–‡ä»¶", key="process_files_button"):
                st.write(f"æ­£åœ¨å¤„ç† {len(unprocessed_files)} ä¸ªä¸Šä¼ çš„æ–‡ä»¶...")
                progress_bar = st.progress(0)
                
                # Create a temporary directory for uploaded images
                upload_folder = "uploaded_img"
                os.makedirs(upload_folder, exist_ok=True)
                
                newly_uploaded_paths = []
                newly_uploaded_embeddings = []

                for i, uploaded_file in enumerate(unprocessed_files):
                    # Check if already processed this session (simple name check)
                    img_path = os.path.join(upload_folder, uploaded_file.name)
                    if img_path not in st.session_state.image_paths:
                        try:
                            # Check file type
                            file_type = uploaded_file.type
                            if file_type == "application/pdf":
                                # Process PDF - returns list of paths and list of embeddings
                                pdf_page_paths, pdf_page_embeddings = process_pdf_file(uploaded_file, cohere_client=co)
                                if pdf_page_paths and pdf_page_embeddings:
                                     # Add only paths/embeddings not already in session state
                                     current_paths_set = set(st.session_state.image_paths)
                                     unique_new_paths = [p for p in pdf_page_paths if p not in current_paths_set]
                                     if unique_new_paths:
                                         indices_to_add = [i for i, p in enumerate(pdf_page_paths) if p in unique_new_paths]
                                         newly_uploaded_paths.extend(unique_new_paths)
                                         newly_uploaded_embeddings.extend([pdf_page_embeddings[idx] for idx in indices_to_add])
                            elif file_type in ["image/png", "image/jpeg"]:
                                # Process regular image
                                # Save the uploaded file
                                with open(img_path, "wb") as f:
                                    f.write(uploaded_file.getbuffer())
                                
                                # Get embedding
                                base64_img = base64_from_image(img_path)
                                emb = compute_image_embedding(base64_img, _cohere_client=co)
                                
                                if emb is not None:
                                    newly_uploaded_paths.append(img_path)
                                    newly_uploaded_embeddings.append(emb)
                            else:
                                 st.warning(f"è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{uploaded_file.name} ({file_type})")
                            
                            # Mark file as processed
                            st.session_state.processed_files.add(uploaded_file.name)

                        except Exception as e:
                            st.error(f"å¤„ç† {uploaded_file.name} æ—¶å‡ºé”™ï¼š{e}")
                    # Update progress regardless of processing status for user feedback
                    progress_bar.progress((i + 1) / len(unprocessed_files))

                # Add newly processed files to session state
                if newly_uploaded_paths:
                    st.session_state.image_paths.extend(newly_uploaded_paths)
                    if newly_uploaded_embeddings:
                        new_embeddings_array = np.vstack(newly_uploaded_embeddings)
                        if st.session_state.doc_embeddings is None or st.session_state.doc_embeddings.size == 0:
                            st.session_state.doc_embeddings = new_embeddings_array
                        else:
                            st.session_state.doc_embeddings = np.vstack((st.session_state.doc_embeddings, new_embeddings_array))
                        st.success(f"æˆåŠŸå¤„ç†å¹¶æ·»åŠ äº† {len(newly_uploaded_paths)} å¼ æ–°å›¾ç‰‡ã€‚")
                    else:
                         st.warning("ä¸ºæ–°ä¸Šä¼ çš„å›¾ç‰‡ç”ŸæˆåµŒå…¥å‘é‡å¤±è´¥ã€‚")
                
                progress_bar.empty()  # Remove progress bar after completion
                st.rerun()  # Refresh to update file status display
        
        elif not co:
            st.warning("è¯·è¾“å…¥ API å¯†é’¥ä»¥å¯ç”¨æ–‡ä»¶å¤„ç†åŠŸèƒ½ã€‚")
        elif not unprocessed_files:
              st.info("æ‰€æœ‰æ–‡ä»¶éƒ½å·²å¤„ç†å®Œæˆã€‚")
    else:
        st.info("è¯·é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶ã€‚")

    # Handle file removal logic
    if not uploaded_files and st.session_state.processed_files:
            # Clear all uploaded file related data
            upload_folder = "uploaded_img"
            indices_to_remove = []
            
            for i, img_path in enumerate(st.session_state.image_paths[:]):
                # Remove uploaded images and PDF pages
                if img_path.startswith(upload_folder) or img_path.startswith("pdf_pages"):
                    indices_to_remove.append(i)
            
            # Remove images and embeddings in reverse order
            for idx in sorted(indices_to_remove, reverse=True):
                if idx < len(st.session_state.image_paths):
                    st.session_state.image_paths.pop(idx)
                    if st.session_state.doc_embeddings is not None and idx < st.session_state.doc_embeddings.shape[0]:
                        st.session_state.doc_embeddings = np.delete(st.session_state.doc_embeddings, idx, axis=0)
            
            # Clear processed files set
            st.session_state.processed_files.clear()
            
            # Clean up empty embeddings array
            if st.session_state.doc_embeddings is not None and st.session_state.doc_embeddings.shape[0] == 0:
                st.session_state.doc_embeddings = None

    # Sync uploaded files with processed data
    if uploaded_files:
        # Get current uploaded file names
        current_uploaded_names = {f.name for f in uploaded_files}
        
        # Remove processed files that are no longer uploaded
        files_to_remove = st.session_state.processed_files - current_uploaded_names
        if files_to_remove:
            # Remove from processed files set
            st.session_state.processed_files -= files_to_remove
            
            # Remove corresponding images and embeddings from session state
            upload_folder = "uploaded_img"
            indices_to_remove = []
            
            for i, img_path in enumerate(st.session_state.image_paths[:]):
                should_remove = False
                
                # Check if this image corresponds to a removed file
                if img_path.startswith(upload_folder):
                    filename = os.path.basename(img_path)
                    if filename in files_to_remove:
                        should_remove = True
                # Also check PDF pages
                elif img_path.startswith("pdf_pages"):
                    # Extract PDF name from path - more precise matching
                    # Path format: pdf_pages/PDF_NAME_WITHOUT_EXTENSION/page_X.png
                    path_parts = img_path.replace("\\", "/").split("/")
                    if len(path_parts) >= 2:
                        pdf_folder_name = path_parts[1]
                        # Check if any removed file matches this PDF folder
                        for removed_file in files_to_remove:
                            if removed_file.endswith('.pdf'):
                                # Get PDF name without extension
                                pdf_name_without_ext = os.path.splitext(removed_file)[0]
                                # Exact match with folder name
                                if pdf_folder_name == pdf_name_without_ext:
                                    should_remove = True
                                    break
                
                if should_remove:
                    indices_to_remove.append(i)
            
            # Remove images and embeddings in reverse order to maintain indices
            for idx in sorted(indices_to_remove, reverse=True):
                if idx < len(st.session_state.image_paths):
                    st.session_state.image_paths.pop(idx)
                    if st.session_state.doc_embeddings is not None and idx < st.session_state.doc_embeddings.shape[0]:
                        st.session_state.doc_embeddings = np.delete(st.session_state.doc_embeddings, idx, axis=0)
            
            # Clean up empty embeddings array
            if st.session_state.doc_embeddings is not None and st.session_state.doc_embeddings.shape[0] == 0:
                st.session_state.doc_embeddings = None
            
            # Show feedback if files were removed
            if indices_to_remove:
                st.info(f"å·²æ¸…ç† {len(indices_to_remove)} å¼ å›¾ç‰‡ï¼ˆå¯¹åº”å·²åˆ é™¤çš„æ–‡ä»¶ï¼‰")

def handle_query_interface(co, genai_client, query_agent, cohere_api_key, google_api_key):
    """å¤„ç†æŸ¥è¯¢ç•Œé¢é€»è¾‘"""
    st.markdown("---")
    st.subheader("â“ æå‡ºé—®é¢˜")

    if not st.session_state.image_paths:
        st.warning("è¯·å…ˆä¸Šä¼ æ‚¨è‡ªå·±çš„å›¾ç‰‡æˆ–PDFã€‚")
    else:
        st.info(f"å‡†å¤‡å›ç­”å…³äº {len(st.session_state.image_paths)} å¼ å›¾ç‰‡çš„é—®é¢˜ã€‚")

        # Display thumbnails of all loaded images (optional)
        with st.expander("æŸ¥çœ‹å·²åŠ è½½çš„å›¾ç‰‡", expanded=False):
            if st.session_state.image_paths:
                num_images_to_show = len(st.session_state.image_paths)
                cols = st.columns(5) # Show 5 thumbnails per row
                for i in range(num_images_to_show):
                    with cols[i % 5]:
                        # Add try-except for missing files during display
                        try:
                             # Display PDF pages differently? For now, just show the image
                             st.image(st.session_state.image_paths[i], width=100, caption=os.path.basename(st.session_state.image_paths[i]))
                        except FileNotFoundError:
                            st.error(f"ç¼ºå¤±ï¼š{os.path.basename(st.session_state.image_paths[i])}")
            else:
                st.write("å°šæœªåŠ è½½ä»»ä½•å›¾ç‰‡ã€‚")

    # Use form to enable Enter key submission
    with st.form(key="rag_form", clear_on_submit=False):
        question = st.text_input("è¯¢é—®å…³äºå·²åŠ è½½å›¾ç‰‡çš„é—®é¢˜ï¼š", 
                                  key="main_question_input",
                                  placeholder="ä¾‹å¦‚ï¼šç»™æˆ‘è®²è§£ä¸‹xxxæ¨¡å‹çš„ç»“æ„ï¼Ÿ",
                                  disabled=not st.session_state.image_paths)
        
        run_button = st.form_submit_button("è¿è¡Œè§†è§‰ RAG", 
                                          disabled=not (cohere_api_key and google_api_key and st.session_state.image_paths and st.session_state.doc_embeddings is not None and st.session_state.doc_embeddings.size > 0))
        
        # Enable form submission when question is entered (even if button is not clicked)
        if question and not run_button:
            run_button = True

    # Output Area
    st.markdown("### ç»“æœ")
    retrieved_images_placeholder = st.empty()
    answer_placeholder = st.empty()

    # Run search and answer logic
    if run_button:
        if co and genai_client and st.session_state.doc_embeddings is not None and len(st.session_state.doc_embeddings) > 0:
            # Ensure embeddings and paths match before search
            if len(st.session_state.image_paths) != st.session_state.doc_embeddings.shape[0]:
                st.error("é”™è¯¯ï¼šå›¾ç‰‡æ•°é‡ä¸åµŒå…¥å‘é‡æ•°é‡ä¸åŒ¹é…ã€‚æ— æ³•ç»§ç»­ã€‚")
            else:
                # Determine search strategy
                if st.session_state.use_query_expansion and query_agent:
                    with st.spinner("æ­£åœ¨æ‰©å±•æŸ¥è¯¢..."):
                        try:
                            expanded_queries = query_agent.expand_query_sync(question)
                            if len(expanded_queries) > 1:
                                st.info(f"ğŸ” æŸ¥è¯¢å·²æ‰©å±•ä¸º {len(expanded_queries)} ä¸ªå˜ä½“")
                                with st.expander("æŸ¥çœ‹æ‰©å±•çš„æŸ¥è¯¢", expanded=False):
                                    for i, eq in enumerate(expanded_queries, 1):
                                        st.write(f"{i}. {eq}")
                            else:
                                st.info("ä½¿ç”¨åŸå§‹æŸ¥è¯¢è¿›è¡Œæœç´¢")
                        except Exception as e:
                            st.warning(f"æŸ¥è¯¢æ‰©å±•å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢ï¼š{e}")
                            expanded_queries = [question]
                    
                    with st.spinner("æ­£åœ¨æ‰§è¡Œå¤šæŸ¥è¯¢èåˆæœç´¢..."):
                        search_results = multi_query_search(expanded_queries, co, st.session_state.doc_embeddings, st.session_state.image_paths, st.session_state.num_results)
                else:
                    with st.spinner("æ­£åœ¨æŸ¥æ‰¾ç›¸å…³å›¾ç‰‡..."):
                        search_results = search(question, co, st.session_state.doc_embeddings, st.session_state.image_paths, st.session_state.num_results)

                if search_results:
                    # Display multiple retrieved images
                    with retrieved_images_placeholder.container():
                        st.markdown(f"**æ£€ç´¢åˆ° {len(search_results)} ä¸ªç›¸å…³ç»“æœï¼š**")
                        
                        # Create columns for displaying images
                        cols = st.columns(min(len(search_results), 3))  # Max 3 columns
                        
                        for i, (img_path, score) in enumerate(search_results):
                            col_idx = i % 3
                            with cols[col_idx]:
                                # Create caption with source info
                                source_info = os.path.basename(img_path)
                                if img_path.startswith("pdf_pages/"):
                                    parts = img_path.split(os.sep)
                                    if len(parts) >= 3:
                                        pdf_name = parts[1]
                                        page_name = parts[-1]
                                        source_info = f"{pdf_name}.pdfï¼Œ{page_name.replace('.png','')}"
                                
                                caption = f"ç»“æœ {i+1}\næ¥æºï¼š{source_info}\nç›¸å…³åº¦ï¼š{score:.3f}"
                                st.image(img_path, caption=caption, use_container_width=True)
                        
                        # If more than 3 results, show remaining in additional rows
                        if len(search_results) > 3:
                            for row_start in range(3, len(search_results), 3):
                                row_end = min(row_start + 3, len(search_results))
                                row_cols = st.columns(row_end - row_start)
                                
                                for i in range(row_start, row_end):
                                    img_path, score = search_results[i]
                                    col_idx = i - row_start
                                    with row_cols[col_idx]:
                                        source_info = os.path.basename(img_path)
                                        if img_path.startswith("pdf_pages/"):
                                            parts = img_path.split(os.sep)
                                            if len(parts) >= 3:
                                                pdf_name = parts[1]
                                                page_name = parts[-1]
                                                source_info = f"{pdf_name}.pdfï¼Œ{page_name.replace('.png','')}"
                                        
                                        caption = f"ç»“æœ {i+1}\næ¥æºï¼š{source_info}\nç›¸å…³åº¦ï¼š{score:.3f}"
                                        st.image(img_path, caption=caption, use_container_width=True)

                    with st.spinner("æ­£åœ¨åŸºäºå¤šä¸ªå›¾ç‰‡ç”Ÿæˆç»¼åˆç­”æ¡ˆ..."):
                        final_answer = answer_multiple(question, search_results, genai_client)
                        answer_placeholder.markdown(f"**ç»¼åˆç­”æ¡ˆï¼š**\n{final_answer}")
                else:
                    retrieved_images_placeholder.warning("æ— æ³•æ‰¾åˆ°ä¸æ‚¨çš„é—®é¢˜ç›¸å…³çš„å›¾ç‰‡ã€‚")
                    answer_placeholder.text("") # Clear answer placeholder
        else:
            # This case should ideally be prevented by the disabled state of the button
            st.error("æ— æ³•è¿è¡Œ RAGã€‚è¯·æ£€æŸ¥ API å®¢æˆ·ç«¯å¹¶ç¡®ä¿å›¾ç‰‡å·²åŠ è½½å¹¶ç”ŸæˆåµŒå…¥å‘é‡ã€‚")

def main():
    """ä¸»å‡½æ•° - åº”ç”¨ç¨‹åºå…¥å£ç‚¹"""
    # --- Streamlit App Configuration ---
    st.set_page_config(layout="wide", page_title="è§†è§‰RAG")
    st.title("è§†è§‰RAG ğŸ–¼ï¸")
    
    # æ£€æŸ¥æŸ¥è¯¢æ‰©å±•ä»£ç†æ˜¯å¦å¯ç”¨
    if QueryExpansionAgent is None:
        st.warning("æŸ¥è¯¢æ‰©å†™ä»£ç†å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹æŸ¥è¯¢æ¨¡å¼ã€‚")
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    initialize_session_state()
    
    # è®¾ç½®ä¾§è¾¹æ å¹¶è·å–APIå¯†é’¥
    cohere_api_key, google_api_key = setup_sidebar()
    
    # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
    co, genai_client, query_agent = initialize_api_clients(cohere_api_key, google_api_key)
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    show_model_info()
    
    # å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    handle_file_upload(co)
    
    # å¤„ç†æŸ¥è¯¢ç•Œé¢
    handle_query_interface(co, genai_client, query_agent, cohere_api_key, google_api_key)
    
    # Footer
    st.markdown("---")
    st.caption("åŸºäº Cohere Embed-4 çš„è§†è§‰æ£€ç´¢å¢å¼ºç”Ÿæˆ | ä½¿ç”¨ Streamlitã€Qwen-3ã€Cohere Embed-4 å’Œ Google Gemini 2.5 Flash æ„å»º")

if __name__ == "__main__":
    main()